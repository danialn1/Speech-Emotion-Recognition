# Speech-Emotion-Recognition


In this project, I implemented a classifier that can determine the emotions concealed in speech
signals. There are many potential applications of SER such as in call centres, health care and human
resources, it will help them to improve their businesses by better understanding of customer emotional
needs. 
Audio speech signals contain a large number of parameters that reflecting emotional characteristics.
Feature selection and feature extraction are vital steps toward building a successful classification models.
In SER, various types of features can be extracted from the speech signals. However, extracting the correct
feature sets is a challenging task.There are three prominent categories in speech features used in SER: (i)
the prosodic features, (ii) the spectral or vocal tract features, and (iii) the excitation source features.
Prosody features are the characteristics of sound generated by the human speech,for example, pitch or
funda- mental frequency (F0),duration and energy.
Spectral features are the characteristics of various sound components generated from different cavities of

the vocal tract system. Some spectrum features are such as linear prediction coefficients (LPC), mel-
frequency cepstrum coefficients (MFCC), and modulation spectral features.

The features used to represent glottal activity, mainly the vibration of glottal folds, are known as
excitation source features. These are also called voice quality features because glottal folds determine the
characteristics of voice. Voice quality measures for a speech signal includes harshness, breathiness, and
tenseness.
